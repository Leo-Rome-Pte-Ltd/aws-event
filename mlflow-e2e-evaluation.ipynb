{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM RAG Evaluation with MLflow Example Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42084110-295b-493a-9b3e-5d8d29ff78b3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Welcome to this comprehensive tutorial on evaluating Retrieval-Augmented Generation (RAG) systems using MLflow. This tutorial is designed to guide you through the intricacies of assessing various RAG systems, focusing on how they can be effectively integrated and evaluated in a real-world context. Whether you are a data scientist, a machine learning engineer, or simply an enthusiast in the field of AI, this tutorial offers valuable insights and practical knowledge.\n",
    "\n",
    "### What You Will Learn:\n",
    "\n",
    "1. **Setting Up the Environment**:\n",
    "   - Learn how to set up your development environment with all the necessary tools and libraries, including MLflow, OpenAI, ChromaDB, LangChain, and more. This section ensures you have everything you need to start working with RAG systems.\n",
    "\n",
    "2. **Understanding RAG Systems**:\n",
    "   - Delve into the concept of Retrieval-Augmented Generation and its significance in modern AI applications. Understand how RAG systems leverage both retrieval and generation capabilities to provide accurate and contextually relevant responses.\n",
    "\n",
    "4. **Deploying and Testing RAG Systems with MLflow**:\n",
    "   - Learn how to create, deploy, and test RAG systems using MLflow. This includes setting up endpoints, deploying models, and querying them to see their responses in action.\n",
    "\n",
    "5. **Evaluating Performance with MLflow**: \n",
    "   - Dive into evaluating the RAG systems using MLflow's evaluation tools. Understand how to use metrics like relevance and latency to assess the performance of your RAG system.\n",
    "\n",
    "6. **Experimenting with Chunking Strategies**:\n",
    "   - Experiment with different text chunking strategies to optimize the performance of RAG systems. Understand how the size of text chunks affects retrieval accuracy and system responsiveness.\n",
    "\n",
    "7. **Creating and Using Evaluation Datasets**:\n",
    "   - Learn how to create and utilize evaluation datasets (Golden Datasets) to effectively assess the performance of your RAG system.\n",
    "\n",
    "8. **Combining Retrieval and Generation for Question Answering**:\n",
    "   - Gain insights into how retrieval and generation components work together in a RAG system to answer questions based on a given context or documentation.\n",
    "\n",
    "By the end of this tutorial, you will have a thorough understanding of how to evaluate and optimize RAG systems using MLflow. You will be equipped with the knowledge to deploy, test, and refine RAG systems, making them suitable for various practical applications. This tutorial is your stepping stone into the world of advanced AI model evaluation and deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d87628a6-ef1d-4586-8080-13f538904076",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "695c9abf-466c-4b34-a901-852a62d9d10f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import getpass\n",
    "import warnings\n",
    "from typing import List\n",
    "\n",
    "import chromadb\n",
    "import mlflow\n",
    "import mlflow.deployments\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")  # noqa\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.embeddings import MlflowEmbeddings\n",
    "from langchain_community.llms import Mlflow\n",
    "from mlflow.metrics.genai.metric_definitions import relevance\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f8dfd16-c064-4a7e-9e3e-226894275e95",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.13.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check mlflow version\n",
    "mlflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "899aa208-48aa-404e-b823-f47e410d9490",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.5.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check chroma version\n",
    "chromadb.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(df):\n",
    "    return display(HTML(df.to_html().replace(\"\\\\n\", \"<br>\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96a5c4f9-8bd7-4e07-8caa-a80133d53433",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create and Test Endpoint on MLflow for AWS Bedrock and OpenAI\n",
    "\n",
    "We will use [MLflow Deployments Server](https://mlflow.org/docs/latest/llms/deployments/index.html) locally to abstract the endpoints. Please run the following command to start the MLflow server:\n",
    "\n",
    "```bash\n",
    "mlflow deployments start-server --config-path mlflow-deployment.yaml --port 5000 --host localhost --workers 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff5ecf97-c82c-4812-8b5b-05734bc2fded",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='completions' endpoint_type='llm/v1/completions' model=RouteModelInfo(name='anthropic.claude-v2:1', provider='bedrock') endpoint_url='http://127.0.0.1:5000/gateway/completions/invocations' limit=None\n",
      "name='chat' endpoint_type='llm/v1/chat' model=RouteModelInfo(name='gpt-4', provider='openai') endpoint_url='http://127.0.0.1:5000/gateway/chat/invocations' limit=None\n",
      "name='embeddings' endpoint_type='llm/v1/embeddings' model=RouteModelInfo(name='text-embedding-ada-002', provider='openai') endpoint_url='http://127.0.0.1:5000/gateway/embeddings/invocations' limit=None\n"
     ]
    }
   ],
   "source": [
    "client = mlflow.deployments.get_deploy_client(\"http://127.0.0.1:5000\")\n",
    "\n",
    "endpoints = client.list_endpoints()\n",
    "\n",
    "for endpoint in endpoints:\n",
    "    print(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e99f3b3-69b3-4a0c-82bb-d39170038b6a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': None, 'object': 'text_completion', 'created': 1717804873, 'model': 'anthropic.claude-v2:1', 'choices': [{'index': 0, 'text': \" Pi is calculated by approximating the ratio of a circle's circumference to its diameter. Modern computations use iterative algorithms to refine the approximation of Pi to extreme precision.\", 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': None, 'completion_tokens': None, 'total_tokens': None}}\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    client.predict(\n",
    "        endpoint=\"completions\",\n",
    "        inputs={\n",
    "            \"prompt\": \"How is Pi calculated? Be very concise.\",\n",
    "            \"max_tokens\": 100,\n",
    "        },\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set MLflow Tracking URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://mlflow-artifacts-767397766072-fd891caf/1', creation_time=1717803484641, experiment_id='1', last_update_time=1717803484641, lifecycle_stage='active', name='llmops-demo', tags={}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow_tracking_uri = getpass.getpass(prompt=\"Enter your MLflow Tracking URI: \")\n",
    "if mlflow_tracking_uri.endswith(\".com\") and (\n",
    "    not mlflow_tracking_uri.startswith(\"http\")\n",
    "):\n",
    "    mlflow_tracking_uri = \"http://\" + mlflow_tracking_uri\n",
    "\n",
    "mlflow.set_tracking_uri(\n",
    "    mlflow_tracking_uri\n",
    ")  # please change this to your MLflow tracking URI\n",
    "mlflow.set_experiment(\"llmops-demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "273d1345-95d7-435a-a7b6-a5f3dbb3f073",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create RAG POC with LangChain and log with MLflow\n",
    "\n",
    "Use Langchain and Chroma to create a RAG system that answers questions based on the MLflow documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7f64bef-116d-48f0-98d7-a18f858a9b64",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1049, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "CHUNK_SIZE = 1000\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    [\n",
    "        \"https://mlflow.org/docs/latest/index.html\",\n",
    "        \"https://mlflow.org/docs/latest/tracking/autolog.html\",\n",
    "        \"https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html\",\n",
    "        \"https://mlflow.org/docs/latest/python_api/mlflow.deployments.html\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# create the language model using MLflow deployment\n",
    "llm = Mlflow(\n",
    "    target_uri=\"http://127.0.0.1:5000\",\n",
    "    endpoint=\"completions\",\n",
    ")\n",
    "\n",
    "# create the embedding function using MLflow deployment\n",
    "embedding_function = MlflowEmbeddings(\n",
    "    target_uri=\"http://127.0.0.1:5000\",\n",
    "    endpoint=\"embeddings\",\n",
    ")\n",
    "docsearch = Chroma.from_documents(texts, embedding_function)\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=docsearch.as_retriever(fetch_k=3),\n",
    "    return_source_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54d629aa-7920-44d9-b896-a987adc5bffb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Evaluate the Vector Database and Retrieval using `mlflow.evaluate()`\n",
    "\n",
    "#### Create an eval dataset (Golden Dataset)\n",
    "\n",
    "We can [leveraging the power of an LLM to generate synthetic data for testing](https://mlflow.org/docs/latest/llms/rag/notebooks/question-generation-retrieval-evaluation.html), offering a creative and efficient alternative. To our readers and customers, we emphasize the importance of crafting a dataset that mirrors the expected inputs and outputs of your RAG application. It's a journey worth taking for the incredible insights you'll gain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6d59ea8-3586-459e-88e4-c3b774e415a9",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "EVALUATION_DATASET_PATH = \"https://raw.githubusercontent.com/mlflow/mlflow/master/examples/llms/RAG/static_evaluation_dataset.csv\"\n",
    "\n",
    "synthetic_eval_data = pd.read_csv(EVALUATION_DATASET_PATH)\n",
    "\n",
    "# Load the static evaluation dataset from disk and deserialize the source and retrieved doc ids\n",
    "synthetic_eval_data[\"source\"] = synthetic_eval_data[\"source\"].apply(ast.literal_eval)\n",
    "synthetic_eval_data[\"retrieved_doc_ids\"] = synthetic_eval_data[\n",
    "    \"retrieved_doc_ids\"\n",
    "].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78650ad4-0ea3-41a4-9298-47b47b1e112f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>source</th>\n",
       "      <th>retrieved_doc_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the purpose of the MLflow Model Registry?</td>\n",
       "      <td>[model-registry.html]</td>\n",
       "      <td>[model-registry.html, introduction/index.html, introduction/index.html, deep-learning/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the purpose of registering a model with the Model Registry?</td>\n",
       "      <td>[model-registry.html]</td>\n",
       "      <td>[model-registry.html, models.html, introduction/index.html, introduction/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What can you do with registered models and model versions?</td>\n",
       "      <td>[model-registry.html]</td>\n",
       "      <td>[model-registry.html, models.html, deployment/deploy-model-to-kubernetes/index.html, deployment/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How can you add, modify, update, or delete a model in the Model Registry?</td>\n",
       "      <td>[model-registry.html]</td>\n",
       "      <td>[model-registry.html, models.html, deployment/deploy-model-to-kubernetes/index.html, introduction/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can you deploy and organize models in the Model Registry?</td>\n",
       "      <td>[model-registry.html]</td>\n",
       "      <td>[model-registry.html, deployment/index.html, deployment/index.html, models.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the purpose of the mlflow.sklearn.log_model() method?</td>\n",
       "      <td>[model-registry.html]</td>\n",
       "      <td>[models.html, getting-started/intro-quickstart/index.html, deployment/deploy-model-to-kubernetes/index.html, getting-started/quickstart-1/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What method do you use to create a new registered model?</td>\n",
       "      <td>[model-registry.html]</td>\n",
       "      <td>[model-registry.html, models.html, deployment/deploy-model-to-kubernetes/index.html, getting-started/quickstart-2/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How can you deploy and organize models in the Model Registry?</td>\n",
       "      <td>[model-registry.html]</td>\n",
       "      <td>[model-registry.html, deployment/index.html, deployment/index.html, models.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How can you fetch a specific model version?</td>\n",
       "      <td>[model-registry.html]</td>\n",
       "      <td>[models.html, model-registry.html, deployment/deploy-model-to-kubernetes/index.html, getting-started/quickstart-2/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How can you fetch the latest model version in a specific stage?</td>\n",
       "      <td>[model-registry.html]</td>\n",
       "      <td>[models.html, model-registry.html, deployment/deploy-model-to-kubernetes/index.html, llms/prompt-engineering/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What can you do to promote MLflow Models across environments?</td>\n",
       "      <td>[model-registry.html]</td>\n",
       "      <td>[deployment/index.html, deployment/index.html, models.html, getting-started/quickstart-2/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>How can you fetch a list of registered models in the MLflow registry?</td>\n",
       "      <td>[model-registry.html]</td>\n",
       "      <td>[model-registry.html, models.html, getting-started/quickstart-2/index.html, tutorials-and-examples/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What is the name of the model and its version details?</td>\n",
       "      <td>[model-registry.html]</td>\n",
       "      <td>[models.html, model-registry.html, new-features/index.html, getting-started/quickstart-2/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What is the purpose of saving the model in pickled format?</td>\n",
       "      <td>[model-registry.html]</td>\n",
       "      <td>[models.html, deployment/deploy-model-to-kubernetes/index.html, model-registry.html, deployment/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What is an MLflow Model and what is its purpose?</td>\n",
       "      <td>[models.html]</td>\n",
       "      <td>[introduction/index.html, introduction/index.html, deployment/index.html, deployment/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What are the flavors defined in the MLmodel file for the mlflow.sklearn library?</td>\n",
       "      <td>[models.html]</td>\n",
       "      <td>[community-model-flavors.html, models.html, traditional-ml/creating-custom-pyfunc/index.html, deployment/deploy-model-to-kubernetes/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>What command can be used to package and deploy models to AWS SageMaker?</td>\n",
       "      <td>[models.html]</td>\n",
       "      <td>[deployment/index.html, deployment/index.html, deployment/deploy-model-to-kubernetes/index.html, models.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>What is the default channel logged for models using MLflow v1.18 and above?</td>\n",
       "      <td>[models.html]</td>\n",
       "      <td>[models.html, tracking.html, new-features/index.html, python_api/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What information is stored in the conda.yaml file?</td>\n",
       "      <td>[models.html]</td>\n",
       "      <td>[models.html, projects.html, tracking.html, cli.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>How can you save a model with a manually specified conda environment?</td>\n",
       "      <td>[models.html]</td>\n",
       "      <td>[models.html, deployment/deploy-model-to-kubernetes/index.html, getting-started/quickstart-1/index.html, getting-started/quickstart-2/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What are inference params and how are they used during model inference?</td>\n",
       "      <td>[models.html]</td>\n",
       "      <td>[models.html, traditional-ml/hyperparameter-tuning-with-child-runs/index.html, getting-started/quickstart-2/index.html, llms/llm-tracking/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>What is the purpose of model signatures in MLflow?</td>\n",
       "      <td>[models.html]</td>\n",
       "      <td>[models.html, model-registry.html, traditional-ml/index.html, traditional-ml/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>What is the API used to set signatures on models?</td>\n",
       "      <td>[models.html]</td>\n",
       "      <td>[models.html, llms/gateway/index.html, model-registry.html, python_api/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What components are used to generate the final time series?</td>\n",
       "      <td>[models.html]</td>\n",
       "      <td>[models.html, introduction/index.html, introduction/index.html, tracking.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>What functionality does the configuration DataFrame submitted to the pyfunc flavor provide?</td>\n",
       "      <td>[models.html]</td>\n",
       "      <td>[models.html, traditional-ml/creating-custom-pyfunc/index.html, community-model-flavors.html, llms/custom-pyfunc-for-llms/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>What is a common configuration for lowering the total memory pressure for pytorch models within transformers pipelines?</td>\n",
       "      <td>[models.html]</td>\n",
       "      <td>[models.html, llms/custom-pyfunc-for-llms/index.html, llms/index.html, llms/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>What does the save_model() function do?</td>\n",
       "      <td>[models.html]</td>\n",
       "      <td>[models.html, model-registry.html, deployment/deploy-model-to-kubernetes/index.html, getting-started/quickstart-1/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>What is an MLflow Project?</td>\n",
       "      <td>[projects.html]</td>\n",
       "      <td>[projects.html, introduction/index.html, introduction/index.html, getting-started/quickstart-1/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>What are the entry points in a MLproject file and how can you specify parameters for them?</td>\n",
       "      <td>[projects.html]</td>\n",
       "      <td>[projects.html, cli.html, llms/prompt-engineering/index.html, tracking.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>What are the project environments supported by MLflow?</td>\n",
       "      <td>[projects.html]</td>\n",
       "      <td>[projects.html, deployment/index.html, deployment/index.html, traditional-ml/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>What is the purpose of the --build-image flag when running mlflow run?</td>\n",
       "      <td>[projects.html]</td>\n",
       "      <td>[cli.html, models.html, getting-started/quickstart-2/index.html, tracking.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>What is the purpose of specifying a Conda environment in an MLflow project?</td>\n",
       "      <td>[projects.html]</td>\n",
       "      <td>[projects.html, models.html, deployment/deploy-model-to-kubernetes/index.html, deployment/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>What is the purpose of the MLproject file?</td>\n",
       "      <td>[projects.html]</td>\n",
       "      <td>[projects.html, introduction/index.html, introduction/index.html, models.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>How can you pass runtime parameters to the entry point of an MLflow Project?</td>\n",
       "      <td>[projects.html]</td>\n",
       "      <td>[projects.html, cli.html, tracking.html, getting-started/quickstart-2/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>What is the relative path to the python_env YAML file within the MLflow project's directory?</td>\n",
       "      <td>[projects.html]</td>\n",
       "      <td>[models.html, projects.html, python_api/index.html, tracking.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>What are the additional local volume mounted and environment variables in the docker container?</td>\n",
       "      <td>[projects.html]</td>\n",
       "      <td>[tracking.html, cli.html, docker.html, models.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>How does MLflow run a Project on Kubernetes?</td>\n",
       "      <td>[projects.html]</td>\n",
       "      <td>[projects.html, deployment/deploy-model-to-kubernetes/index.html, getting-started/quickstart-2/index.html, deployment/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>What fields are replaced when MLflow creates a Kubernetes Job for an MLflow Project?</td>\n",
       "      <td>[projects.html]</td>\n",
       "      <td>[projects.html, models.html, tracking.html, deployment/deploy-model-to-kubernetes/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>What is the syntax for searching runs using the MLflow UI and API?</td>\n",
       "      <td>[search-runs.html]</td>\n",
       "      <td>[search-runs.html, getting-started/quickstart-2/index.html, llms/prompt-engineering/index.html, tracking.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>What is the syntax for searching runs using the MLflow UI and API?</td>\n",
       "      <td>[search-runs.html]</td>\n",
       "      <td>[search-runs.html, getting-started/quickstart-2/index.html, llms/prompt-engineering/index.html, tracking.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>What are the key parts of a search expression in MLflow?</td>\n",
       "      <td>[search-runs.html]</td>\n",
       "      <td>[search-runs.html, models.html, introduction/index.html, introduction/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>What are some examples of entity names that contain special characters?</td>\n",
       "      <td>[search-runs.html]</td>\n",
       "      <td>[tutorials-and-examples/index.html, models.html, search-runs.html, llms/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>What are the key attributes for the model with the run_id 'a1b2c3d4' and run_name 'my-run'?</td>\n",
       "      <td>[search-runs.html]</td>\n",
       "      <td>[search-runs.html, tracking.html, models.html, cli.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>What type of constant does the RHS need to be if LHS is a metric?</td>\n",
       "      <td>[search-runs.html]</td>\n",
       "      <td>[llms/llm-evaluate/index.html, model-evaluation/index.html, model-evaluation/index.html, models.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>How can you get all active runs from experiments IDs 3, 4, and 17 that used a CNN model with 10 layers and had a prediction accuracy of 94.5% or higher?</td>\n",
       "      <td>[search-runs.html]</td>\n",
       "      <td>[models.html, getting-started/quickstart-2/index.html, search-runs.html, tutorials-and-examples/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>What is the purpose of the 'experimentIds' variable in the given paragraph?</td>\n",
       "      <td>[search-runs.html]</td>\n",
       "      <td>[search-experiments.html, cli.html, models.html, rest-api.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>What is the MLflow Tracking component used for?</td>\n",
       "      <td>[tracking.html]</td>\n",
       "      <td>[introduction/index.html, introduction/index.html, tracking.html, llms/llm-tracking/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>What information does each run record in MLflow Tracking?</td>\n",
       "      <td>[tracking.html]</td>\n",
       "      <td>[tracking.html, llms/llm-tracking/index.html, traditional-ml/hyperparameter-tuning-with-child-runs/index.html, getting-started/intro-quickstart/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>How can you create an experiment in MLflow?</td>\n",
       "      <td>[tracking.html]</td>\n",
       "      <td>[getting-started/quickstart-1/index.html, getting-started/quickstart-2/index.html, models.html, getting-started/logging-first-model/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>How can you create an experiment using MLflow?</td>\n",
       "      <td>[tracking.html]</td>\n",
       "      <td>[getting-started/quickstart-2/index.html, getting-started/quickstart-1/index.html, models.html, tutorials-and-examples/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>What are the two components used by MLflow for storage?</td>\n",
       "      <td>[tracking.html]</td>\n",
       "      <td>[tracking.html, introduction/index.html, introduction/index.html, models.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>What interfaces does the MLflow client use to record MLflow entities and artifacts when running MLflow on a local machine with a SQLAlchemy-compatible database?</td>\n",
       "      <td>[tracking.html]</td>\n",
       "      <td>[tracking.html, models.html, plugins.html, getting-started/quickstart-1/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>What is the default backend store used by MLflow?</td>\n",
       "      <td>[tracking.html]</td>\n",
       "      <td>[tracking.html, plugins.html, models.html, cli.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>What is the architecture depicted in this example scenario?</td>\n",
       "      <td>[tracking.html]</td>\n",
       "      <td>[tutorials-and-examples/index.html, models.html, deployment/deploy-model-to-kubernetes/index.html, traditional-ml/index.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>What information does autologging capture when launching short-lived MLflow runs?</td>\n",
       "      <td>[tracking.html]</td>\n",
       "      <td>[tracking.html, getting-started/quickstart-1/index.html, llms/llm-tracking/index.html, models.html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>What is the purpose of the --serve-artifacts flag?</td>\n",
       "      <td>[tracking.html]</td>\n",
       "      <td>[tracking.html, cli.html, deployment/index.html, deployment/index.html]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretty_print(synthetic_eval_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33374a05-1992-4361-9c7b-3b1e1f8169cc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Evaluating the Embedding Model with MLflow\n",
    "\n",
    "In this part of the tutorial, we focus on evaluating the embedding model's performance in the context of a retrieval system. The process involves a series of steps to assess how effectively the model can retrieve relevant documents based on given questions.\n",
    "\n",
    "#### Creating Evaluation Data\n",
    "- We start by defining a set of questions and their corresponding source URLs. This `eval_data` DataFrame acts as our evaluation dataset, allowing us to test the model's ability to link questions to the correct source documents.\n",
    "\n",
    "#### The `evaluate_embedding` Function\n",
    "- The `evaluate_embedding` function is designed to assess the performance of a given embedding function.\n",
    "- **Chunking Strategy**: The function begins by splitting a list of documents into chunks using a `CharacterTextSplitter`. The size of these chunks is crucial, as it can influence the retrieval accuracy.\n",
    "- **Retriever Initialization**: We then use `Chroma.from_documents` to create a retriever with the specified embedding function. This retriever is responsible for finding documents relevant to a given query.\n",
    "- **Retrieval Process**: The function defines a `retriever_model_function` that applies the retriever to each question in the evaluation dataset. It retrieves document IDs that the model finds most relevant for each question.\n",
    "\n",
    "#### MLflow Evaluation\n",
    "- With `mlflow.start_run()`, we initiate an evaluation run. `mlflow.evaluate` is then called to evaluate our retriever model function against the evaluation dataset.\n",
    "- We use the default evaluator with specified targets to assess the model's performance.\n",
    "- The results of this evaluation, stored in `eval_results_of_retriever_df_bge`, are displayed, providing insights into the effectiveness of the embedding model in document retrieval.\n",
    "\n",
    "#### Further Evaluation with Metrics\n",
    "- Additionally, we perform a more detailed evaluation using various metrics like precision, recall, and NDCG at different 'k' values. These metrics offer a deeper understanding of the model's retrieval accuracy and ranking effectiveness.\n",
    "\n",
    "This evaluation step is integral to understanding the strengths and weaknesses of our embedding model in a real-world RAG system. By analyzing these results, we can make informed decisions about model adjustments or optimizations to improve overall system performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30e2ac2a-40e7-4fb5-8850-95e51013a269",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "eval_data = pd.DataFrame(\n",
    "    {\n",
    "        \"question\": [\n",
    "            \"What is MLflow?\",\n",
    "            \"What is Databricks?\",\n",
    "            \"How to serve a model on Databricks?\",\n",
    "            \"How to enable MLflow Autologging for my workspace by default?\",\n",
    "        ],\n",
    "        \"source\": [\n",
    "            [\"https://mlflow.org/docs/latest/index.html\"],\n",
    "            [\n",
    "                \"https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html\"\n",
    "            ],\n",
    "            [\"https://mlflow.org/docs/latest/python_api/mlflow.deployments.html\"],\n",
    "            [\"https://mlflow.org/docs/latest/tracking/autolog.html\"],\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de0be80f-2e00-4d3a-b05f-63c4c4359efe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1049, which is longer than the specified 1000\n",
      "2024/06/08 07:01:37 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "2024/06/08 07:01:40 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "Downloading artifacts: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>source</th>\n",
       "      <th>outputs</th>\n",
       "      <th>precision_at_3/score</th>\n",
       "      <th>recall_at_3/score</th>\n",
       "      <th>ndcg_at_3/score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is MLflow?</td>\n",
       "      <td>[https://mlflow.org/docs/latest/index.html]</td>\n",
       "      <td>[https://mlflow.org/docs/latest/index.html, https://mlflow.org/docs/latest/index.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html]</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is Databricks?</td>\n",
       "      <td>[https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html]</td>\n",
       "      <td>[https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to serve a model on Databricks?</td>\n",
       "      <td>[https://mlflow.org/docs/latest/python_api/mlflow.deployments.html]</td>\n",
       "      <td>[https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.530721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to enable MLflow Autologging for my workspace by default?</td>\n",
       "      <td>[https://mlflow.org/docs/latest/tracking/autolog.html]</td>\n",
       "      <td>[https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_embedding(embedding_function):\n",
    "    list_of_documents = loader.load()\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=0)\n",
    "    docs = text_splitter.split_documents(list_of_documents)\n",
    "    retriever = Chroma.from_documents(docs, embedding_function).as_retriever()\n",
    "\n",
    "    def retrieve_doc_ids(question: str) -> List[str]:\n",
    "        docs = retriever.get_relevant_documents(question)\n",
    "        return [doc.metadata[\"source\"] for doc in docs]\n",
    "\n",
    "    def retriever_model_function(question_df: pd.DataFrame) -> pd.Series:\n",
    "        return question_df[\"question\"].apply(retrieve_doc_ids)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        return mlflow.evaluate(\n",
    "            model=retriever_model_function,\n",
    "            data=eval_data,\n",
    "            model_type=\"retriever\",\n",
    "            targets=\"source\",\n",
    "            evaluators=\"default\",\n",
    "        )\n",
    "\n",
    "\n",
    "result1 = evaluate_embedding(\n",
    "    MlflowEmbeddings(\n",
    "        target_uri=\"http://127.0.0.1:5000\",\n",
    "        endpoint=\"embeddings\",\n",
    "    )\n",
    ")\n",
    "# To validate the results of a different model, comment out the above line and uncomment the below line:\n",
    "# result2 = evaluate_embedding(SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\"))\n",
    "\n",
    "eval_results_of_retriever_df_bge = result1.tables[\"eval_results_table\"]\n",
    "# To validate the results of a different model, comment out the above line and uncomment the below line:\n",
    "# eval_results_of_retriever_df_MiniLM = result2.tables[\"eval_results_table\"]\n",
    "pretty_print(eval_results_of_retriever_df_bge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7fecbb62-44ec-4af4-aa5a-7aa79bfa0943",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Evaluate different Top K strategy with MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95a3acd8-170b-4e14-bc51-da977d2b1939",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/08 07:02:20 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "Downloading artifacts: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>precision_at_3/score</th>\n",
       "      <th>recall_at_3/score</th>\n",
       "      <th>ndcg_at_3/score</th>\n",
       "      <th>source</th>\n",
       "      <th>outputs</th>\n",
       "      <th>precision_at_1/score</th>\n",
       "      <th>precision_at_2/score</th>\n",
       "      <th>recall_at_1/score</th>\n",
       "      <th>recall_at_2/score</th>\n",
       "      <th>ndcg_at_1/score</th>\n",
       "      <th>ndcg_at_2/score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is MLflow?</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[https://mlflow.org/docs/latest/index.html]</td>\n",
       "      <td>[https://mlflow.org/docs/latest/index.html, https://mlflow.org/docs/latest/index.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is Databricks?</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html]</td>\n",
       "      <td>[https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to serve a model on Databricks?</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.530721</td>\n",
       "      <td>[https://mlflow.org/docs/latest/python_api/mlflow.deployments.html]</td>\n",
       "      <td>[https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.386853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to enable MLflow Autologging for my workspace by default?</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[https://mlflow.org/docs/latest/tracking/autolog.html]</td>\n",
       "      <td>[https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    evaluate_results = mlflow.evaluate(\n",
    "        data=eval_results_of_retriever_df_bge,\n",
    "        targets=\"source\",\n",
    "        predictions=\"outputs\",\n",
    "        evaluators=\"default\",\n",
    "        extra_metrics=[\n",
    "            mlflow.metrics.precision_at_k(1),\n",
    "            mlflow.metrics.precision_at_k(2),\n",
    "            mlflow.metrics.precision_at_k(3),\n",
    "            mlflow.metrics.recall_at_k(1),\n",
    "            mlflow.metrics.recall_at_k(2),\n",
    "            mlflow.metrics.recall_at_k(3),\n",
    "            mlflow.metrics.ndcg_at_k(1),\n",
    "            mlflow.metrics.ndcg_at_k(2),\n",
    "            mlflow.metrics.ndcg_at_k(3),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "pretty_print(evaluate_results.tables[\"eval_results_table\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74a52bda-1ea7-4f50-abac-e36d78e1b96b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Evaluate the Chunking Strategy with MLflow\n",
    "\n",
    "In the realm of RAG systems, the strategy for dividing text into chunks plays a pivotal role in both retrieval effectiveness and the overall system performance. Let's delve into why and how we evaluate different chunking strategies:\n",
    "\n",
    "#### Importance of Chunking:\n",
    "- **Influences Retrieval Accuracy**: The way text is chunked can significantly affect the retrieval component of RAG systems. Smaller chunks may lead to more focused and relevant document retrieval, while larger chunks might capture broader context.\n",
    "- **Impacts System's Responsiveness**: The size of text chunks also influences the speed of document retrieval and processing. Smaller chunks can be processed more quickly but may require the system to evaluate more chunks overall.\n",
    "\n",
    "#### Evaluating Different Chunk Sizes:\n",
    "- **Purpose**: By evaluating different chunk sizes, we aim to find an optimal balance between retrieval accuracy and processing efficiency. This involves experimenting with various chunk sizes to see how they impact the system's performance.\n",
    "- **Method**: We create text chunks of different sizes (e.g., 1000 characters, 2000 characters) and then evaluate how each chunking strategy affects the RAG system. Key aspects to observe include the relevance of retrieved documents and the system's latency.\n",
    "\n",
    "In this example below, we're using the default evaluation suite to provide a comprehensive adjudication of the quality of the responses to retrieved document contents to determine what the impact to the quality of the returned references are, allowing us to explore and tune the chunk size in order to arrive at a configuration that best handles our suite of test questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2c6bff7-d988-4f09-ac10-6c9ea14b9242",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_text_splitters.base:Created a chunk of size 418, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 359, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 375, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 142, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 745, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 122, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 231, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 284, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 264, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 443, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 129, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 152, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 146, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 157, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 132, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 248, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 496, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 137, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 305, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 114, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 228, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 323, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 224, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 163, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 468, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 216, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 254, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 449, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 199, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 161, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 104, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 411, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 249, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 567, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 328, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 294, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 280, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 166, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 457, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 104, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 221, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 136, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 204, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 151, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 197, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 158, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 104, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 214, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 375, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 240, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 163, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 400, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 149, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 583, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 108, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 130, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 163, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 272, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 266, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 119, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 282, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 152, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 126, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 376, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 131, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 142, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 229, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 253, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 670, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 155, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 147, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 162, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 163, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 160, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 107, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 356, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 372, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 169, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 147, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 277, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 114, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 193, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 129, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 228, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 841, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 136, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 316, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1049, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 629, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 315, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 114, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 617, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 453, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 559, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 214, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 236, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 232, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 184, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 315, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 214, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 156, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 424, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 135, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 228, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 388, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 223, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 454, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 112, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 229, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 447, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 214, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 241, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 227, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 134, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 150, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 153, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 607, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 530, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 426, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 127, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 167, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 139, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 369, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 170, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 136, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 767, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 135, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 129, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 335, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 128, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 369, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 154, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 139, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 713, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 122, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 804, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 173, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 140, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 771, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 414, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 454, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 177, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 111, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 348, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 317, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 296, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 122, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 641, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 243, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 200, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 195, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 106, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 127, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 188, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 165, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 131, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 453, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 229, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 775, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 226, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 265, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 284, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 120, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 115, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 224, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 152, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 225, which is longer than the specified 100\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 103, which is longer than the specified 100\n",
      "2024/06/08 07:03:55 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "2024/06/08 07:03:58 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1049, which is longer than the specified 1000\n",
      "2024/06/08 07:04:12 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "2024/06/08 07:04:15 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "2024/06/08 07:04:25 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "2024/06/08 07:04:27 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "Downloading artifacts: 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>source</th>\n",
       "      <th>outputs</th>\n",
       "      <th>precision_at_3/score</th>\n",
       "      <th>recall_at_3/score</th>\n",
       "      <th>ndcg_at_3/score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is MLflow?</td>\n",
       "      <td>[https://mlflow.org/docs/latest/index.html]</td>\n",
       "      <td>[https://mlflow.org/docs/latest/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/index.html, https://mlflow.org/docs/latest/index.html]</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.919721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is Databricks?</td>\n",
       "      <td>[https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html]</td>\n",
       "      <td>[https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html]</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.919721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to serve a model on Databricks?</td>\n",
       "      <td>[https://mlflow.org/docs/latest/python_api/mlflow.deployments.html]</td>\n",
       "      <td>[https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.530721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to enable MLflow Autologging for my workspace by default?</td>\n",
       "      <td>[https://mlflow.org/docs/latest/tracking/autolog.html]</td>\n",
       "      <td>[https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>source</th>\n",
       "      <th>outputs</th>\n",
       "      <th>precision_at_3/score</th>\n",
       "      <th>recall_at_3/score</th>\n",
       "      <th>ndcg_at_3/score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is MLflow?</td>\n",
       "      <td>[https://mlflow.org/docs/latest/index.html]</td>\n",
       "      <td>[https://mlflow.org/docs/latest/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/index.html, https://mlflow.org/docs/latest/index.html]</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.919721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is Databricks?</td>\n",
       "      <td>[https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html]</td>\n",
       "      <td>[https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html]</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.919721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to serve a model on Databricks?</td>\n",
       "      <td>[https://mlflow.org/docs/latest/python_api/mlflow.deployments.html]</td>\n",
       "      <td>[https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.530721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to enable MLflow Autologging for my workspace by default?</td>\n",
       "      <td>[https://mlflow.org/docs/latest/tracking/autolog.html]</td>\n",
       "      <td>[https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>source</th>\n",
       "      <th>outputs</th>\n",
       "      <th>precision_at_3/score</th>\n",
       "      <th>recall_at_3/score</th>\n",
       "      <th>ndcg_at_3/score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is MLflow?</td>\n",
       "      <td>[https://mlflow.org/docs/latest/index.html]</td>\n",
       "      <td>[https://mlflow.org/docs/latest/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/index.html, https://mlflow.org/docs/latest/index.html]</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.919721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is Databricks?</td>\n",
       "      <td>[https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html]</td>\n",
       "      <td>[https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html]</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.919721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to serve a model on Databricks?</td>\n",
       "      <td>[https://mlflow.org/docs/latest/python_api/mlflow.deployments.html]</td>\n",
       "      <td>[https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.530721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to enable MLflow Autologging for my workspace by default?</td>\n",
       "      <td>[https://mlflow.org/docs/latest/tracking/autolog.html]</td>\n",
       "      <td>[https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_chunk_size(chunk_size):\n",
    "    list_of_documents = loader.load()\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=0)\n",
    "    docs = text_splitter.split_documents(list_of_documents)\n",
    "    embedding_function = MlflowEmbeddings(\n",
    "        target_uri=\"http://127.0.0.1:5000\",\n",
    "        endpoint=\"embeddings\",\n",
    "    )\n",
    "    retriever = Chroma.from_documents(docs, embedding_function).as_retriever()\n",
    "\n",
    "    def retrieve_doc_ids(question: str) -> List[str]:\n",
    "        docs = retriever.get_relevant_documents(question)\n",
    "        return [doc.metadata[\"source\"] for doc in docs]\n",
    "\n",
    "    def retriever_model_function(question_df: pd.DataFrame) -> pd.Series:\n",
    "        return question_df[\"question\"].apply(retrieve_doc_ids)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        return mlflow.evaluate(\n",
    "            model=retriever_model_function,\n",
    "            data=eval_data,\n",
    "            model_type=\"retriever\",\n",
    "            targets=\"source\",\n",
    "            evaluators=\"default\",\n",
    "        )\n",
    "\n",
    "\n",
    "result1 = evaluate_chunk_size(100)\n",
    "result2 = evaluate_chunk_size(1000)\n",
    "result3 = evaluate_chunk_size(5000)\n",
    "\n",
    "pretty_print(result1.tables[\"eval_results_table\"])\n",
    "pretty_print(result2.tables[\"eval_results_table\"])\n",
    "pretty_print(result3.tables[\"eval_results_table\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd45cf0e-e139-4059-a2bd-6e4fc4d5d36e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Evaluate the RAG system using `mlflow.evaluate()`\n",
    "\n",
    "In this section, we'll delve into evaluating the Retrieval-Augmented Generation (RAG) systems using `mlflow.evaluate()`. This evaluation is crucial for assessing the effectiveness and efficiency of RAG systems in question-answering contexts. We focus on two key metrics: `relevance_metric` and `latency`.\n",
    "\n",
    "#### Relevance Metric:\n",
    "- **What It Measures**: The `relevance_metric` quantifies how relevant the RAG system's answers are to the input questions. This metric is critical for understanding the accuracy and contextual appropriateness of the system's responses.\n",
    "- **Why It's Important**: In question-answering systems, relevance is paramount. The ability of a RAG system to provide accurate and contextually correct answers determines its utility and effectiveness in real-world applications, such as information retrieval and customer support.\n",
    "- **Tutorial Context**: Within our tutorial, we utilize the `relevance_metric` to evaluate the quality of answers provided by the RAG system. It serves as a quantitative measure of the system's content accuracy, reflecting its capability to generate useful and precise responses.\n",
    "\n",
    "#### Latency:\n",
    "- **What It Measures**: The `latency` metric captures the response time of the RAG system. It measures the duration taken by the system to generate an answer after receiving a query.\n",
    "- **Why It's Important**: Response time is a critical factor in user experience. In interactive systems, lower latency leads to a more efficient and satisfying user experience. High latency, conversely, can be detrimental to user satisfaction.\n",
    "- **Tutorial Context**: In this tutorial, we assess the system's efficiency in terms of response time through the `latency` metric. This evaluation is vital for understanding the system's performance in a production environment, where timely responses are as important as their accuracy.\n",
    "\n",
    "To start with evaluating, we'll create a simple function that runs each input through the RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "667ec809-2bb5-4170-9937-6804386b41ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def model(input_df):\n",
    "    return input_df[\"questions\"].map(qa).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1064306-b7f3-4b3e-825c-4353d808f21d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create an evaluation dataset (Golden Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5481491-e4a9-42ea-8a3f-f527faffd04d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is MLflow?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is Databricks?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to serve a model on Databricks?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to enable MLflow Autologging for my workspace by default?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_df = pd.DataFrame(\n",
    "    {\n",
    "        \"questions\": [\n",
    "            \"What is MLflow?\",\n",
    "            \"What is Databricks?\",\n",
    "            \"How to serve a model on Databricks?\",\n",
    "            \"How to enable MLflow Autologging for my workspace by default?\",\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "pretty_print(eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77f56ede-0b2d-449f-868c-e3a561ef28d0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Evaluate using LLM as a Judge and Basic Metrics\n",
    "\n",
    "In this concluding section of the tutorial, we perform a final evaluation of our RAG system using MLflow's powerful evaluation tools. This evaluation is crucial for assessing the performance and efficiency of the question-answering model.\n",
    "\n",
    "#### Key Steps in the Evaluation:\n",
    "\n",
    "1. **Setting the Deployment Target**:\n",
    "   - The deployment target is set to MLflow Deployments Server, enabling us to retrieve all available endpoints. This is essential for accessing our deployed models.\n",
    "\n",
    "2. **Relevance Metric Setup**:\n",
    "   - We initialize the `relevance` metric using a model hosted on MLflow Deployments Server. This metric assesses how relevant the answers generated by our RAG system are in response to the input questions.\n",
    "\n",
    "3. **Running the Evaluation**:\n",
    "   - An MLflow run is initiated, and `mlflow.evaluate()` is called to evaluate our RAG model against the prepared evaluation dataset.\n",
    "   - The model is evaluated as a \"question-answering\" system using default evaluators.\n",
    "   - Additional metrics, including the `relevance_metric` and `latency`, are specified. These metrics provide insights into the relevance of the answers and the response time of the model.\n",
    "   - The `evaluator_config` maps the input questions and context, ensuring the correct evaluation of the RAG system.\n",
    "\n",
    "4. **Results and Metrics Display**:\n",
    "   - The results of the evaluation, including key metrics, are displayed in a table format, providing a clear and structured view of the model's performance based on relevance and latency.\n",
    "\n",
    "This comprehensive evaluation step is vital for understanding the effectiveness and efficiency of our RAG system. By assessing both the relevance of the answers and the latency of the responses, we gain a holistic view of the model's performance, guiding any further optimization or deployment decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a290ca1c-11c9-4025-9025-70807479f1e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/08 07:04:41 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "2024/06/08 07:05:06 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "2024/06/08 07:05:09 WARNING mlflow.metrics.metric_definitions: Failed to load 'toxicity' metric (error: ModuleNotFoundError(\"No module named 'evaluate'\")), skipping metric logging.\n",
      "2024/06/08 07:05:09 WARNING mlflow.models.evaluation.default_evaluator: Did not log builtin metric 'toxicity' because it returned None.\n",
      "2024/06/08 07:05:09 WARNING mlflow.models.evaluation.default_evaluator: Did not log builtin metric 'exact_match' because it returned None.\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.82s/it]\n",
      "2024/06/08 07:05:14 WARNING mlflow.metrics.metric_definitions: Failed to load 'toxicity' metric (error: ModuleNotFoundError(\"No module named 'evaluate'\")), skipping metric logging.\n",
      "2024/06/08 07:05:14 WARNING mlflow.models.evaluation.default_evaluator: Did not log builtin metric 'toxicity' because it returned None.\n",
      "2024/06/08 07:05:14 WARNING mlflow.models.evaluation.default_evaluator: Did not log builtin metric 'exact_match' because it returned None.\n",
      "100%|██████████| 4/4 [00:05<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'latency/mean': 6.2395822405815125, 'latency/variance': 3.1304196862583176, 'latency/p90': 7.731202101707458, 'flesch_kincaid_grade_level/v1/mean': 9.25, 'flesch_kincaid_grade_level/v1/variance': 7.5024999999999995, 'flesch_kincaid_grade_level/v1/p90': 12.17, 'ari_grade_level/v1/mean': 12.375, 'ari_grade_level/v1/variance': 11.926875000000003, 'ari_grade_level/v1/p90': 15.920000000000002, 'relevance/v1/mean': 4.75, 'relevance/v1/variance': 0.1875, 'relevance/v1/p90': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>latency</th>\n",
       "      <th>token_count</th>\n",
       "      <th>flesch_kincaid_grade_level/v1/score</th>\n",
       "      <th>ari_grade_level/v1/score</th>\n",
       "      <th>relevance/v1/score</th>\n",
       "      <th>relevance/v1/justification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is MLflow?</td>\n",
       "      <td>3.343102</td>\n",
       "      <td>50</td>\n",
       "      <td>12.5</td>\n",
       "      <td>16.1</td>\n",
       "      <td>5</td>\n",
       "      <td>The output provides a comprehensive answer to the question about what MLflow is. It uses the provided context effectively to explain that MLflow is an open-source platform designed to manage the machine learning lifecycle, making each stage manageable, traceable, and reproducible. The output is entirely relevant to the input and context.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is Databricks?</td>\n",
       "      <td>7.509839</td>\n",
       "      <td>164</td>\n",
       "      <td>11.4</td>\n",
       "      <td>15.5</td>\n",
       "      <td>5</td>\n",
       "      <td>The output provides a comprehensive answer to the question about what Databricks is. It uses the provided context effectively to explain the key features of Databricks, its usage, and its relevance to big data and machine learning. The output is highly relevant and directly addresses the input question.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to serve a model on Databricks?</td>\n",
       "      <td>6.279316</td>\n",
       "      <td>156</td>\n",
       "      <td>6.9</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5</td>\n",
       "      <td>The output provides a comprehensive answer to the question about how to serve a model on Databricks. It uses the provided context effectively, detailing the steps required to serve a model on Databricks, and highlighting the difference between the production workspace and the free Community Edition. The output is highly relevant and directly addresses the input question.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to enable MLflow Autologging for my workspace by default?</td>\n",
       "      <td>7.826072</td>\n",
       "      <td>162</td>\n",
       "      <td>6.2</td>\n",
       "      <td>8.4</td>\n",
       "      <td>4</td>\n",
       "      <td>The output provides a relevant and accurate response to the question about enabling MLflow Autologging by default. It provides a step-by-step guide and also mentions the need for more specific information about the workspace and code structure. However, it could be improved by providing more specific examples or details about how to set an environment variable to always call it, which would make the response more comprehensive.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlflow.deployments.set_deployments_target(\"http://127.0.0.1:5000\")\n",
    "mlflow.deployments.get_deployments_target()\n",
    "\n",
    "relevance_metric = relevance(model=\"endpoints:/chat\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    results = mlflow.evaluate(\n",
    "        model,\n",
    "        eval_df,\n",
    "        model_type=\"question-answering\",\n",
    "        evaluators=\"default\",\n",
    "        predictions=\"result\",\n",
    "        extra_metrics=[relevance_metric, mlflow.metrics.latency()],\n",
    "        evaluator_config={\n",
    "            \"col_mapping\": {\n",
    "                \"inputs\": \"questions\",\n",
    "                \"context\": \"source_documents\",\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "    print(results.metrics)\n",
    "\n",
    "pretty_print(\n",
    "    results.tables[\"eval_results_table\"].drop(columns=[\"outputs\", \"source_documents\"])\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [
    {
     "elements": [
      {
       "dashboardResultIndex": 0,
       "elementNUID": "f55e4f48-684d-4903-8bd0-06ca638dcea9",
       "elementType": "command",
       "guid": "f9125ba6-77fb-411f-9859-66be60ebd6a5",
       "options": null,
       "position": {
        "height": 12,
        "width": 22,
        "x": 0,
        "y": 0,
        "z": null
       },
       "resultIndex": null
      }
     ],
     "globalVars": {},
     "guid": "",
     "layoutOption": {
      "grid": true,
      "stack": true
     },
     "nuid": "5cc44542-d2d1-4b49-9760-7d912cbd5a44",
     "origId": 2038904942228793,
     "title": "Untitled",
     "version": "DashboardViewV1",
     "width": 1024
    }
   ],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "MLflow for e2e Evaluation Blog",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "mlflow-dev-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
